V
Vm
Zm
ej
Zb
s
Zb <- Z - X.b.shrink(X, bhat, state=s)
Zb
bhat
tmp <- as.list(rep(NA, ns))#
        bhat <- matrix(NA, ns, p)#
        ## equi-distant state vector for initialization#
        state <- sort(sample(1:ns, size=K[3], replace=TRUE, prob=(rep(1, ns))))#
        ## median.s <- ceiling(apply(attr(mcmcout, "Smat"), 2, median))#
        end <- c(which(diff(state) == 1), Time)#
        start <- c(1, which(diff(state) == 1)+1)#
        for (j in 1:ns){#
            XM <- NULL;#
            for(h in 1:p){#
                XM <- cbind(XM, c(X[,,start[j]:end[j],h]))#
            }#
            ## vectorized regression#
            tmp[[j]] <- lm(c(Z[,,start[j]:end[j]])~ -1 + XM )#
            bhat[j,] <- tmp[[j]]$coef#
        }
bhat
ns
start
j = 2
XM <- NULL;#
            for(h in 1:p){#
                XM <- cbind(XM, c(X[,,start[j]:end[j],h]))#
            }
dim(XM)
lm(c(Z[,,start[j]:end[j]])~ -1 + XM )
XM
Z[,,start[j]:end[j]]
Z <-  array(qnorm( rank(Y, ties.method="random")/(length(Y)+1) ), dim=K)#
    for(k in 1:K[3]) {#
        Z[,,k] <-  (Z[,,k] + t(Z[,,k]))/sqrt(2)#
    }
Z
Z <-  array(qnorm( rank(Y, ties.method="random")/(length(Y)+1) ), dim=K)#
    for(k in 1:K[3]) {#
        Z[,,k] <-  (Z[,,k] + t(Z[,,k]))/sqrt(2)#
    }
## function call#
    ptm <- proc.time()#
    call <- match.call()#
    mf <- match.call(expand.dots = FALSE)#
#
    ## for future use#
    fast = FALSE#
    sticky = FALSE#
    sequential = FALSE#
    local.type = "NULL" ## c("NULL", "linear.trend", "logistic"),#
    logistic.tune = 0.5#
    random.perturb = TRUE#
    totiter <- mcmc + burnin#
    nstore <- mcmc/thin    #
    reduce.mcmc <- nstore#
    ## changepoint priors and inputs#
    ns <- m + 1 # number of states#
    ## X <- array(1, dim=c(K, 1))#
    p <- dim(X)[4]#
    K <- dim(Y)  #
    Time <- K[3]#
#
    ## Y to Z transformation#
    Z <-  array(qnorm( rank(Y, ties.method="random")/(length(Y)+1) ), dim=K)#
    for(k in 1:K[3]) {#
        Z[,,k] <-  (Z[,,k] + t(Z[,,k]))/sqrt(2)#
    }#
    ## tmp <- as.list(rep(NA, K[3]))#
    ## nodenames <- dimnames(Y)[[1]]#
    ## X0 is a upper triangle matrix of X#
    X0 <- X ;#
    for(k in 1:p) {#
        tmp <- X0[,,,k] ; tmp[!UTA] <- 0 ; X0[,,,k] <- tmp#
    }#
    ## XtX.0 <- apply(X0,c(1,2), function(x){x%*%t(x) } ) #
    XtX.middle <- apply(X0,c(1,2,3), function(x){x%*%t(x) } ) #
    XtX <- matrix(apply(XtX.middle, 1, sum), p, p)#
    if(p==1) {#
        XtX <- matrix(sum(X0^2), p, p)#
    }#
    ## time specific XtX generator#
    XtX.specific <- as.list(rep(NA, Time))#
    for(t in 1:Time){#
        XtX.middle.specific <- apply(X0[,,t,], c(1,2), function(x){x%*%t(x) } ) ## 16 66 66 array#
        XtX.specific[[t]] <- matrix(apply(XtX.middle.specific, 1, sum), p, p)#
        if(p==1) {#
            XtX.specific[[t]] <- matrix(sum(X0[,,t,]^2), p, p)#
        }#
    }#
    rm(XtX.middle.specific)#
    ## unique values of Y#
    uy <- sort(unique(c(Y)))#
    ## prior for changepoint#
    P  <-  NetworkChange:::trans.mat.prior(m=m, n=Time, a = 0.9, b= 0.1)#
    A0  <-  NetworkChange:::trans.mat.prior(m=m, n=Time, a = a, b = b)#
    nss <- 0#
    ## if (is.null(initial.V)){#
    ## out <- startUV(Z, R, K)#
    ## initial.U <- out[[1]]#
    ## V <- out[[2]]#
    ## MU <- M.U(list(U,U,V))#
    if(is.null(u0)){#
        u0 <- 10#
    }#
    if(is.null(u1)){#
        u1 <- 1 #
    }#
    ## sigma.mu <- mean(apply(V, 2, mean))#
    ## sigma.var <- var(apply(V, 2, mean))#
    if(is.null(v0)){#
        v0 <- 10#
        ## v0 <- 4 + 2 * (sigma.mu^2/sigma.var)#
    }#
    if(is.null(v1)){#
        ## v1 <- 1#
        v1 <- K[3]#
    }#
#################################
    ## beta set up#
    ## initialize beta#
#################################
    ## pooling#
    if(pooling.mode == "time.pool"){#
        XM <- NULL;#
        for(j in 1:p){#
            XM <- cbind(XM, c(X[,,,j]))#
        }#
        ## vectorized regression#
        tmp <- lm( c(Z)~-1+ XM )#
        bhat <- tmp$coef#
        Zb <-  Z- X.b(X, bhat)#
        bhat.mat <- matrix(NA, nstore, p)#
    }else if(pooling.mode == "time.specific"){#
        tmp <- as.list(rep(NA, K[3]))#
        bhat <- matrix(NA, Time, p)#
        for (t in 1:Time){#
            XM <- NULL;#
            for(j in 1:p){#
                XM <- cbind(XM, c(X[,,t,j]))#
            }#
            ## vectorized regression#
            tmp[[t]] <- lm(c(Z[,,t])~-1+ XM )#
            bhat[t,] <- tmp[[t]]$coef#
        }#
        Zb <- Z - X.b.specific(X, bhat)#
        bhat.mat <- matrix(NA, nstore, p*Time)#
#
    }else{#
        ## time.shrink#
        tmp <- as.list(rep(NA, ns))#
        bhat <- matrix(NA, ns, p)#
        ## equi-distant state vector for initialization#
        state <- sort(sample(1:ns, size=K[3], replace=TRUE, prob=(rep(1, ns))))#
        ## median.s <- ceiling(apply(attr(mcmcout, "Smat"), 2, median))#
        end <- c(which(diff(state) == 1), Time)#
        start <- c(1, which(diff(state) == 1)+1)#
        for (j in 1:ns){#
            XM <- NULL;#
            for(h in 1:p){#
                XM <- cbind(XM, c(X[,,start[j]:end[j],h]))#
            }#
            ## vectorized regression#
            tmp[[j]] <- lm(c(Z[,,start[j]:end[j]])~ -1 + XM )#
            bhat[j,] <- tmp[[j]]$coef#
        } #
        Zb <- Z - X.b.shrink(X, bhat, state)#
        bhat.mat <- matrix(NA, nstore, p*ns)#
    }#
    if (is.null(initial.s)){#
        s <- state## startS(Z, Time, m, initial.U, V, s2=1, R)#
    } else{#
        s <- initial.s#
    }#
    ## holder #
    ## Zm is a state-specific holder of ZE = Z - bhat#
    ## Zm[[1]] is a subset of Z pertaining to state 1#
    ## ZU = Z - ULU#
    ## ZY is original Z separated by state#
    UTA <- Km <- Zm <- ZY <- ZU <- ej <- U <- MU <- MU.state <- Xm <- Vm <- as.list(rep(NA, ns))#
    ps.store <- matrix(0, Time, ns)#
    ## given the state vector, initialize regime specific U and Vm#
    for (j in 1:ns){#
        ej[[j]] <- as.numeric(s==j)#
        Zm[[j]] <- Zb[,,ej[[j]]==1] #
        tmp <- eigen(apply(Zm[[j]], c(1,2), mean))#
        d2m <- abs(tmp$val)#
        U0 <- tmp$vec[, order(d2m, decreasing=TRUE) ]#
        U[[j]] <- matrix(U0[, 1:R], nrow=nrow(U0), ncol=R)#
        Vm[[j]] <- matrix(d2m[1:R], sum(s==j), R, byrow=TRUE)#
    }#
    ## V <- Reduce(rbind, Vm)#
    ## initialize MU and MU.state#
    ## MU is regime-specific mean matrix, the length of which depends on regime length#
    ## MU.state is a full-length mean matrix for state sampling#
    for (j in 1:ns){#
        MU[[j]] <-  M.U(list(U[[j]],U[[j]], Vm[[j]]))#
        MU.state[[j]] <-  M.U(list(U[[j]],U[[j]],V))#
    }#
    MUU <- abind(MU)#
#
    ## initialize s2 and d0#
    if (is.null(c0)){#
        c0 <- 1#
    }#
    if(is.null(d0)) {#
        d0 <- var(as.vector(Z - MU.state[[1]]))#
    }#
    s2 <- 1/rgamma(ns, c0/2, (d0)/2)#
    Pmat <- matrix(NA, nstore, ns)#
    ## cat("scale prior for sigma2: ", d0, "\n")#
    ## MCMC holders#
    ## outlier <- rep(0, T) ## count the number of times of -Inf#
    MU.record <- Umat <- s2mat <- iVU <- eU <- eV <- iVV <- eUmat <- iVUmat <- eVmat <- iVVmat <- as.list(rep(NA, ns))#
    for(j in 1:ns){#
        s2mat[[j]] <- matrix(NA, nstore)#
        Umat[[j]] <- matrix(NA, nstore, K[1]*R)#
        eUmat[[j]] <- matrix(NA, nstore, R)#
        iVUmat[[j]] <- matrix(NA, nstore, R*R)#
        eVmat[[j]]  <- matrix(NA, nstore, R)#
        iVVmat[[j]] <- matrix(NA, nstore, R*R)#
        MU.record[[j]] <- Y*0#
        iVU[[j]] <- diag(R)#
        eU[[j]] <- rep(u0, R)#
        iVV[[j]] <- diag(R)#
        eV[[j]] <- rep(v0, R)#
    }#
    Vmat <- matrix(NA, nstore, R*K[3])#
    Smat <- matrix(NA, nstore, K[3])#
    ## loglike holder#
    N.upper.tri <- K[1]*(K[1]-1)/2#
    ## Z.loglike <- matrix(NA, mcmc, K[3])#
    ## Z.loglike <- as(matrix(NA, mcmc, K[3]), "mpfr")#
    if(Waic){#
        Z.loglike.array <- array(NA, dim=c(nstore, N.upper.tri, K[3]))#
    }#
    logmarglike <- loglike <- logmarglike.upper <- loglike.upper <- NA#
#
    Zt <- matrix(NA,  Time,  N.upper.tri)#
    UTAsingle <-  upper.tri(Z[,,1])#
    ## UTA array: TRUE for upper triangle#
    UTAall <- Z*NA#
    for(k in 1:K[3]) {#
        UTAall[,,k] <-  upper.tri(Z[,,1] )#
    } #
    UTAall <- (UTAall==1)#
    Waic.out <- NA#
    SOS <- 0#
    if(verbose !=0){#
        cat("@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ \n")#
        cat("\t NetworkChangeReg Sampler Starts! \n")#
        ## cat("\t function called: ")#
        ## print(call)#
        cat("\t degree normalization: ", degree.normal, "\n")#
        cat("\t initial states: ", table(s), "\n")#
        cat("@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ \n")#
    }
## pooling#
        if(pooling.mode == "time.pool"){#
            EZ <-  X.b(X,bhat) + MUU#
        }else if(pooling.mode == "time.specific"){#
            EZ <- X.b.specific(X, bhat) + MUU#
        }else{#
            EZ <- X.b.shrink(X, bhat, state=s) + MUU #
        }#
        for(y in sample(uy))#
        { #
            lb <- suppressWarnings(max(Z[Y<y & UTAall])) #
            ub <- suppressWarnings(min(Z[Y>y & UTAall]))#
            z <- qnorm(runif(sum(Y==y), pnorm( lb-EZ[Y==y] ), pnorm(ub-EZ[Y==y])))#
            Z[Y==y] <-  EZ[Y==y] + z#
            ## print(y)#
        }
## cat("\n---------------------------------------------- \n ")#
        for (j in 1:ns){#
            ej[[j]] <- as.numeric(s==j)#
            Km[[j]] <- dim(Zb[,,ej[[j]]==1])#
            ## in case state j has only 1 unit, force it to be an array with 1 length#
            if(is.na(Km[[j]][3])){#
                ZY[[j]] <- array(Z[,,ej[[j]]==1], dim = c(Km[[j]][1], Km[[j]][2], sum(ej[[j]]==1)))#
                Zm[[j]] <- array(Zb[,,ej[[j]]==1], dim = c(Km[[j]][1], Km[[j]][2], sum(ej[[j]]==1)))#
                Xm[[j]] <- array(X[,,ej[[j]]==1, ], dim = c(Km[[j]][1], Km[[j]][2], sum(ej[[j]]==1), p))#
                ## ZU[[j]] <- array(Z[,,ej[[j]]==1] - MU[[j]], dim = c(Km[[j]][1], Km[[j]][2], sum(ej[[j]]==1)))#
                 ## Ym[[j]] <- array(Y[,,ej[[j]]==1], dim = c(Km[[j]][1], Km[[j]][2], 1))#
            } else{#
                ZY[[j]] <- Z[,,ej[[j]]==1]#
                Zm[[j]] <- Zb[,,ej[[j]]==1]#
                Xm[[j]] <- array(X[,,ej[[j]]==1, ], dim = c(Km[[j]][1], Km[[j]][2], sum(ej[[j]]==1), p))#
                ## ZU[[j]] <- Z[,,ej[[j]]==1] - MU[[j]]#
                ## Ym[[j]] <- Y[,,ej[[j]]==1]#
            }#
            ## return the right dimension info#
            Km[[j]] <- dim(Zm[[j]])#
#
            ## UTA array: TRUE for upper triangle#
            UTA[[j]] <- Zm[[j]]*NA#
            for(k in 1:Km[[j]][3]) {#
                UTA[[j]][,,k] <-  upper.tri(Zm[[j]][,,1])#
            } #
            UTA[[j]] <- (UTA[[j]]==1)#
        }
## cat("\n---------------------------------------------- \n ")#
        U <- NetworkChange::updateUm(ns, U, V, R, Zm, Km, ej, s2, eU, iVU, UL.Normal)#
        ## Step 3. update V#
        ## cat("\n---------------------------------------------- \n ")#
        ## cat("Step 3. update V \n")#
        ## cat("\n---------------------------------------------- \n ")#
        Vm <- NetworkChange::updateVm(ns, U, V, Zm, Km, R, s2, eV, iVV, UTA)#
        V <- Reduce(rbind, Vm)
V
U
U <- NetworkChange::updateUm(ns, U, V, R, Zm, Km, ej, s2, eU, iVU, UL.Normal)
Vm <- NetworkChange::updateVm(ns, U, V, Zm, Km, R, s2, eV, iVV, UTA)#
        V <- Reduce(rbind, Vm)#
#
        ## update MU#
        for(j in 1:ns){#
            ## MU is shorter than MU.state. MU.state is a full length.#
            MU[[j]] <- M.U(list(U[[j]],U[[j]],Vm[[j]]))#
            MU.state[[j]] <- M.U(list(U[[j]],U[[j]],V))#
            ZU[[j]] <- ZY[[j]] - MU[[j]]#
        }#
        MUU <- abind(MU)
s2 <- NetworkChange::updates2m(ns, Zm, MU, c0, d0, Km)#
        ## update bhat#
        ## pooling#
        if(pooling.mode == "time.pool"){#
            ZE <- Z - MUU#
            Xtz <- t(apply(X0,4,c))%*%c(ZE)#
            cV <- solve( XtX + diag(1/100,p))#
            cE <- cV%*%Xtz#
            bhat <- rmvnorm(1,cE,cV)#
            Zb <-  Z- X.b(X, bhat)            #
        }else if(pooling.mode == "time.specific"){#
            for (t in 1:Time){#
                ZE <- Z[,,t] - MUU[,,t]#
                Xtz <-  t(apply(X0[,,t,],3,c))%*%c(ZE)#
                cV <- solve(XtX.specific[[t]] + diag(1/B0, p))#
                cE <- cV%*%Xtz#
                bhat[t, ] <- rmvnorm(1,cE,cV)#
            }#
            Zb <- Z - X.b.specific(X, bhat)            #
        }else{#
            end <- c(which(diff(s) == 1), Time)#
            start <- c(1, which(diff(s) == 1)+1)#
            for (j in 1:ns){#
                ZE <- ZY[[j]] - MU[[j]]#
                Xtz <-  t(apply(Xm[[j]],4,c))%*%c(ZE)#
                XtX.middle <- apply(Xm[[j]],c(1,2,3), function(x){x%*%t(x) } ) ## 16 66 66  8 array#
                XtX <- matrix(apply(XtX.middle, 1, sum), p, p)#
                cV <- solve( XtX + diag(1/100,p))#
                cE <- cV%*%Xtz#
                ## vectorized regression#
                bhat[j,] <- rmvnorm(1,cE,cV)#
            } #
            Zb <- Z - X.b.shrink(X, bhat, state=s)#
        }
## hierarchical parameters for U#
        for(j in 1:ns){#
            SS <-  t(U[[j]]) %*% U[[j]]## (Km[[j]][1]-1)*cov(U[[j]]) + Km[[j]][1]*msi/(Km[[j]][1]+1)#
            for(r in 1:R){#
                iVU[[j]][r,r] <- 1/rgamma(1, (u0 + K[1])/2, (u1+ SS[r,r])/2)#
            }#
            eU[[j]] <- c(NetworkChange:::rMVNorm(1,apply(U[[j]],2,sum)/(Km[[j]][1]+1), solve(iVU[[j]])/(Km[[j]][1]+1)))#
        }#
        ## hierarchical parameters for V#
        ## V for state j only#
        for(j in 1:ns){#
            Vs <- matrix(Vm[[j]], nrow=sum(ej[[j]]), ncol=R)#
            SS <-  t(Vs)%*%Vs#
            for(r in 1:R){#
                iVV[[j]][r,r] <- 1/rgamma(1, (v0 + Km[[j]][3])/2, (v1 + SS[r,r])/2)#
            }#
            eV[[j]] <- c(NetworkChange:::rMVNorm(1,apply(Vs, 2, sum)/(Km[[j]][3]+1),#
                                                 solve(iVV[[j]])/(Km[[j]][3]+1)))      #
        }
state.out <- NetworkChange::updateS(iter, s, V, m, Zb, Zt, Time, MU.state, P, s2,#
                             N.upper.tri, random.perturb)
s <- state.out$s#
        ps <- state.out$ps#
        ## double check #
        if(length(table(s)) < ns){#
            ## print(table(s))#
            ## cat("Sampled s does not have all states. \n")#
            s <- sort(sample(1:ns, size=K[3], replace=TRUE, prob=(rep(1, ns))))#
        }
s
d <- sapply(1:K[3], function(t){dnorm(c(Zb[,,t][UTAsingle]),#
                                                      mean = c(MU.state[[s[t]]][,,t][UTAsingle]),#
                                                      sd=sqrt(s2[[s[t]]]), log=TRUE)})#
                Z.loglike.array[(iter-burnin)/thin, ,] <- d
Z.loglike.array <- array(NA, dim=c(nstore, N.upper.tri, K[3]))
d <- sapply(1:K[3], function(t){dnorm(c(Zb[,,t][UTAsingle]),#
                                                      mean = c(MU.state[[s[t]]][,,t][UTAsingle]),#
                                                      sd=sqrt(s2[[s[t]]]), log=TRUE)})#
                Z.loglike.array[(iter-burnin)/thin, ,] <- d
d
##############################################################
    ## MCMC loop starts!#
##############################################################
    for(iter in 1:totiter) {#
#
        ## Step 0. Update Z#
        ## update Z#
        ## pooling#
        if(pooling.mode == "time.pool"){#
            EZ <-  X.b(X,bhat) + MUU#
        }else if(pooling.mode == "time.specific"){#
            EZ <- X.b.specific(X, bhat) + MUU#
        }else{#
            EZ <- X.b.shrink(X, bhat, state=s) + MUU #
        }#
        for(y in sample(uy))#
        { #
            lb <- suppressWarnings(max(Z[Y<y & UTAall])) #
            ub <- suppressWarnings(min(Z[Y>y & UTAall]))#
            z <- qnorm(runif(sum(Y==y), pnorm( lb-EZ[Y==y] ), pnorm(ub-EZ[Y==y])))#
            Z[Y==y] <-  EZ[Y==y] + z#
            ## print(y)#
        }#
        ## Step 1. update ej, Km, Zm#
        ## cat("\n---------------------------------------------- \n ")#
        ## cat("Step 1. update ej, Km, Zm \n")#
        ## cat("\n---------------------------------------------- \n ")#
        for (j in 1:ns){#
            ej[[j]] <- as.numeric(s==j)#
            Km[[j]] <- dim(Zb[,,ej[[j]]==1])#
            ## in case state j has only 1 unit, force it to be an array with 1 length#
            if(is.na(Km[[j]][3])){#
                ZY[[j]] <- array(Z[,,ej[[j]]==1], dim = c(Km[[j]][1], Km[[j]][2], sum(ej[[j]]==1)))#
                Zm[[j]] <- array(Zb[,,ej[[j]]==1], dim = c(Km[[j]][1], Km[[j]][2], sum(ej[[j]]==1)))#
                Xm[[j]] <- array(X[,,ej[[j]]==1, ], dim = c(Km[[j]][1], Km[[j]][2], sum(ej[[j]]==1), p))#
                ## ZU[[j]] <- array(Z[,,ej[[j]]==1] - MU[[j]], dim = c(Km[[j]][1], Km[[j]][2], sum(ej[[j]]==1)))#
                 ## Ym[[j]] <- array(Y[,,ej[[j]]==1], dim = c(Km[[j]][1], Km[[j]][2], 1))#
            } else{#
                ZY[[j]] <- Z[,,ej[[j]]==1]#
                Zm[[j]] <- Zb[,,ej[[j]]==1]#
                Xm[[j]] <- array(X[,,ej[[j]]==1, ], dim = c(Km[[j]][1], Km[[j]][2], sum(ej[[j]]==1), p))#
                ## ZU[[j]] <- Z[,,ej[[j]]==1] - MU[[j]]#
                ## Ym[[j]] <- Y[,,ej[[j]]==1]#
            }#
            ## return the right dimension info#
            Km[[j]] <- dim(Zm[[j]])#
#
            ## UTA array: TRUE for upper triangle#
            UTA[[j]] <- Zm[[j]]*NA#
            for(k in 1:Km[[j]][3]) {#
                UTA[[j]][,,k] <-  upper.tri(Zm[[j]][,,1])#
            } #
            UTA[[j]] <- (UTA[[j]]==1)#
        }#
        ## Step 2. update U#
        ## cat("\n---------------------------------------------- \n ")#
        ## cat("Step 2. update U \n")#
        ## cat("\n---------------------------------------------- \n ")#
        U <- NetworkChange::updateUm(ns, U, V, R, Zm, Km, ej, s2, eU, iVU, UL.Normal)#
        ## Step 3. update V#
        ## cat("\n---------------------------------------------- \n ")#
        ## cat("Step 3. update V \n")#
        ## cat("\n---------------------------------------------- \n ")#
        Vm <- NetworkChange::updateVm(ns, U, V, Zm, Km, R, s2, eV, iVV, UTA)#
        V <- Reduce(rbind, Vm)#
#
        ## update MU#
        for(j in 1:ns){#
            ## MU is shorter than MU.state. MU.state is a full length.#
            MU[[j]] <- M.U(list(U[[j]],U[[j]],Vm[[j]]))#
            MU.state[[j]] <- M.U(list(U[[j]],U[[j]],V))#
            ZU[[j]] <- ZY[[j]] - MU[[j]]#
        }#
        MUU <- abind(MU)#
        ## Step 4. update s2#
        ## cat("\n---------------------------------------------- \n ")#
        ## cat("Step 4. update s2 \n")#
        ## cat("\n---------------------------------------------- \n ")#
        s2 <- NetworkChange::updates2m(ns, Zm, MU, c0, d0, Km)#
        ## update bhat#
        ## pooling#
        if(pooling.mode == "time.pool"){#
            ZE <- Z - MUU#
            Xtz <- t(apply(X0,4,c))%*%c(ZE)#
            cV <- solve( XtX + diag(1/100,p))#
            cE <- cV%*%Xtz#
            bhat <- rmvnorm(1,cE,cV)#
            Zb <-  Z- X.b(X, bhat)            #
        }else if(pooling.mode == "time.specific"){#
            for (t in 1:Time){#
                ZE <- Z[,,t] - MUU[,,t]#
                Xtz <-  t(apply(X0[,,t,],3,c))%*%c(ZE)#
                cV <- solve(XtX.specific[[t]] + diag(1/B0, p))#
                cE <- cV%*%Xtz#
                bhat[t, ] <- rmvnorm(1,cE,cV)#
            }#
            Zb <- Z - X.b.specific(X, bhat)            #
        }else{#
            end <- c(which(diff(s) == 1), Time)#
            start <- c(1, which(diff(s) == 1)+1)#
            for (j in 1:ns){#
                ZE <- ZY[[j]] - MU[[j]]#
                Xtz <-  t(apply(Xm[[j]],4,c))%*%c(ZE)#
                XtX.middle <- apply(Xm[[j]],c(1,2,3), function(x){x%*%t(x) } ) ## 16 66 66  8 array#
                XtX <- matrix(apply(XtX.middle, 1, sum), p, p)#
                cV <- solve( XtX + diag(1/100,p))#
                cE <- cV%*%Xtz#
                ## vectorized regression#
                bhat[j,] <- rmvnorm(1,cE,cV)#
            } #
            Zb <- Z - X.b.shrink(X, bhat, state=s)#
        }#
        ## update hierarchical parameters#
        ## hierarchical parameters for U#
        for(j in 1:ns){#
            SS <-  t(U[[j]]) %*% U[[j]]## (Km[[j]][1]-1)*cov(U[[j]]) + Km[[j]][1]*msi/(Km[[j]][1]+1)#
            for(r in 1:R){#
                iVU[[j]][r,r] <- 1/rgamma(1, (u0 + K[1])/2, (u1+ SS[r,r])/2)#
            }#
            eU[[j]] <- c(NetworkChange:::rMVNorm(1,apply(U[[j]],2,sum)/(Km[[j]][1]+1), solve(iVU[[j]])/(Km[[j]][1]+1)))#
        }#
        ## hierarchical parameters for V#
        ## V for state j only#
        for(j in 1:ns){#
            Vs <- matrix(Vm[[j]], nrow=sum(ej[[j]]), ncol=R)#
            SS <-  t(Vs)%*%Vs#
            for(r in 1:R){#
                iVV[[j]][r,r] <- 1/rgamma(1, (v0 + Km[[j]][3])/2, (v1 + SS[r,r])/2)#
            }#
            eV[[j]] <- c(NetworkChange:::rMVNorm(1,apply(Vs, 2, sum)/(Km[[j]][3]+1),#
                                                 solve(iVV[[j]])/(Km[[j]][3]+1)))      #
        }#
        ## Step 5. update s#
        ## cat("\n---------------------------------------------- \n ")#
        ## cat("Step 5. update s \n")#
        ## cat("\n---------------------------------------------- \n ")#
        state.out <- NetworkChange::updateS(iter, s, V, m, Zb, Zt, Time, MU.state, P, s2,#
                             N.upper.tri, random.perturb)#
        ## state.out <- updateS(iter, s, V, m, Zb, Zt, Time, fast,#
        ##                       MU.state, P, s2, local.type, logistic.tune, N.upper.tri, sticky)#
        s <- state.out$s#
        ps <- state.out$ps#
        ## double check #
        if(length(table(s)) < ns){#
            ## print(table(s))#
            ## cat("Sampled s does not have all states. \n")#
            s <- sort(sample(1:ns, size=K[3], replace=TRUE, prob=(rep(1, ns))))#
        }#
        ## Step 6. update P#
        ## cat("\n---------------------------------------------- \n ")#
        ## cat("Step 6. update P \n")#
        ## cat("\n---------------------------------------------- \n ")       #
        P <- NetworkChange::updateP(s, ns, P, A0)#
        ## report#
        if (verbose!= 0 &iter %% verbose == 0){#
            cat("\n----------------------------------------------",'\n')#
            cat("    iteration = ", iter, '\n')#
            ## cat("    SOS = ", SOS, '\n')#
            cat("    beta = ", bhat,'\n')#
            if(plotZ == TRUE & plotUU == TRUE){#
                if(ns < 4){#
                    par(mfrow=c(1, ns+1))#
                } else{#
                    par(mfrow=c(2, ceiling((ns+1)/2)))#
                }#
            }#
            if(plotZ == TRUE){#
                plot(density(c(Z)), lwd=2, main="Density of Z and MU.state")#
                for(j in 1:ns){lines(density(c(MU.state[[j]])), col=1+j)}#
                legend("topright", paste0("Regime", 1:ns), col=2:(ns+1), lty=1, lwd=1)#
            }#
            if(plotZ == FALSE & plotUU == TRUE){#
                par(mfrow=c(1, ns))#
            }#
            for(j in 1:ns){#
                cat("    state ", j, "has :", sum(s==j),'\n')#
                cat("    sigma2 at state", j, "=", s2[j] ,'\n')#
                if(plotUU == TRUE){#
                    plot(U[[j]][,1], U[[j]][, 2], pch=19, cex=1); abline(v=0, col=2); abline(h=0, col=2)#
                }           #
            }#
            cat("----------------------------------------------",'\n')#
        }#
        ## save#
        if (iter > burnin & (iter-burnin)%%thin == 0){#
            nss <- nss + 1#
#
            bhat.mat[iter-burnin, ] <- bhat#
#
            for(j in 1:ns){#
                MU.record[[j]] <- MU.record[[j]] + MU.state[[j]]#
                s2mat[[j]][(iter-burnin)/thin] <- s2[j]#
                Umat[[j]][(iter-burnin)/thin, ] <- as.vector(U[[j]])#
                eUmat[[j]][(iter-burnin)/thin, ] <- as.vector(eU[[j]])#
                iVUmat[[j]][(iter-burnin)/thin, ] <- as.vector(iVU[[j]])#
                eVmat[[j]][(iter-burnin)/thin, ] <- as.vector(eV[[j]])#
                iVVmat[[j]][(iter-burnin)/thin, ] <- as.vector(iVV[[j]])#
            }#
            Vmat[(iter-burnin)/thin, ] <- as.vector(V)#
            Smat[(iter-burnin)/thin, ] <- s#
            Pmat[(iter-burnin)/thin, ] <- diag(P)#
            ps.store <- ps.store + ps#
            if(Waic){#
                d <- sapply(1:K[3], function(t){dnorm(c(Zb[,,t][UTAsingle]),#
                                                      mean = c(MU.state[[s[t]]][,,t][UTAsingle]),#
                                                      sd=sqrt(s2[[s[t]]]), log=TRUE)})#
                Z.loglike.array[(iter-burnin)/thin, ,] <- d#
            }#
        }#
    }## end of MCMC loop
V
U
bhat
end <- c(which(diff(s) == 1), Time)#
            start <- c(1, which(diff(s) == 1)+1)
j=2
ZE <- ZY[[j]] - MU[[j]]#
                Xtz <-  t(apply(Xm[[j]],4,c))%*%c(ZE)
dim(Xtz)
Xtz
s
t(apply(Xm[[j]],4,c))
c(ZE)
dim(t(apply(X0[,,t,],3,c)))
ZE <- Z - MUU#
            Xtz <- t(apply(X0,4,c))%*%c(ZE)#
            cV <- solve( XtX + diag(1/100,p))#
            cE <- cV%*%Xtz#
            bhat <- rmvnorm(1,cE,cV)
bhat
cE
cV
t(apply(X0,4,c))
dim(t(apply(X0,4,c)))
c(ZE)
t(apply(X0,4,c))%*%c(ZE)
dim(X0)
first <- t(apply(X0,4,c))
first[1,]
dim(ZE)
dim(first)
sum(first[1,]*c(ZE))
sum(Y)
mean(Y)
Y <- dat$CC
ptm <- proc.time()#
    call <- match.call()#
    mf <- match.call(expand.dots = FALSE)#
#
    ## for future use#
    fast = FALSE#
    sticky = FALSE#
    sequential = FALSE#
    local.type = "NULL" ## c("NULL", "linear.trend", "logistic"),#
    logistic.tune = 0.5#
    random.perturb = TRUE#
    totiter <- mcmc + burnin#
    nstore <- mcmc/thin    #
    reduce.mcmc <- nstore#
    ## changepoint priors and inputs#
    ns <- m + 1 # number of states#
    ## X <- array(1, dim=c(K, 1))#
    p <- dim(X)[4]#
    K <- dim(Y)  #
    Time <- K[3]#
#
    ## Y to Z transformation#
    Z <-  array(qnorm( rank(Y, ties.method="random")/(length(Y)+1) ), dim=K)#
    for(k in 1:K[3]) {#
        Z[,,k] <-  (Z[,,k] + t(Z[,,k]))/sqrt(2)#
    }#
    ## tmp <- as.list(rep(NA, K[3]))#
    ## nodenames <- dimnames(Y)[[1]]#
    ## X0 is a upper triangle matrix of X#
    X0 <- X ;#
    for(k in 1:p) {#
        tmp <- X0[,,,k] ; tmp[!UTA] <- 0 ; X0[,,,k] <- tmp#
    }#
    ## XtX.0 <- apply(X0,c(1,2), function(x){x%*%t(x) } ) #
    XtX.middle <- apply(X0,c(1,2,3), function(x){x%*%t(x) } ) #
    XtX <- matrix(apply(XtX.middle, 1, sum), p, p)#
    if(p==1) {#
        XtX <- matrix(sum(X0^2), p, p)#
    }#
    ## time specific XtX generator#
    XtX.specific <- as.list(rep(NA, Time))#
    for(t in 1:Time){#
        XtX.middle.specific <- apply(X0[,,t,], c(1,2), function(x){x%*%t(x) } ) ## 16 66 66 array#
        XtX.specific[[t]] <- matrix(apply(XtX.middle.specific, 1, sum), p, p)#
        if(p==1) {#
            XtX.specific[[t]] <- matrix(sum(X0[,,t,]^2), p, p)#
        }#
    }#
    rm(XtX.middle.specific)#
    ## unique values of Y#
    uy <- sort(unique(c(Y)))#
    ## prior for changepoint#
    P  <-  NetworkChange:::trans.mat.prior(m=m, n=Time, a = 0.9, b= 0.1)#
    A0  <-  NetworkChange:::trans.mat.prior(m=m, n=Time, a = a, b = b)#
    nss <- 0#
    ## if (is.null(initial.V)){#
    ## out <- startUV(Z, R, K)#
    ## initial.U <- out[[1]]#
    ## V <- out[[2]]#
    ## MU <- M.U(list(U,U,V))#
    if(is.null(u0)){#
        u0 <- 10#
    }#
    if(is.null(u1)){#
        u1 <- 1 #
    }#
    ## sigma.mu <- mean(apply(V, 2, mean))#
    ## sigma.var <- var(apply(V, 2, mean))#
    if(is.null(v0)){#
        v0 <- 10#
        ## v0 <- 4 + 2 * (sigma.mu^2/sigma.var)#
    }#
    if(is.null(v1)){#
        ## v1 <- 1#
        v1 <- K[3]#
    }#
#################################
    ## beta set up#
    ## initialize beta#
#################################
    ## pooling#
    if(pooling.mode == "time.pool"){#
        XM <- NULL;#
        for(j in 1:p){#
            XM <- cbind(XM, c(X[,,,j]))#
        }#
        ## vectorized regression#
        tmp <- lm( c(Z)~-1+ XM )#
        bhat <- tmp$coef#
        Zb <-  Z- X.b(X, bhat)#
        bhat.mat <- matrix(NA, nstore, p)#
    }else if(pooling.mode == "time.specific"){#
        tmp <- as.list(rep(NA, K[3]))#
        bhat <- matrix(NA, Time, p)#
        for (t in 1:Time){#
            XM <- NULL;#
            for(j in 1:p){#
                XM <- cbind(XM, c(X[,,t,j]))#
            }#
            ## vectorized regression#
            tmp[[t]] <- lm(c(Z[,,t])~-1+ XM )#
            bhat[t,] <- tmp[[t]]$coef#
        }#
        Zb <- Z - X.b.specific(X, bhat)#
        bhat.mat <- matrix(NA, nstore, p*Time)#
#
    }else{#
        ## time.shrink#
        tmp <- as.list(rep(NA, ns))#
        bhat <- matrix(NA, ns, p)#
        ## equi-distant state vector for initialization#
        state <- sort(sample(1:ns, size=K[3], replace=TRUE, prob=(rep(1, ns))))#
        ## median.s <- ceiling(apply(attr(mcmcout, "Smat"), 2, median))#
        end <- c(which(diff(state) == 1), Time)#
        start <- c(1, which(diff(state) == 1)+1)#
        for (j in 1:ns){#
            XM <- NULL;#
            for(h in 1:p){#
                XM <- cbind(XM, c(X[,,start[j]:end[j],h]))#
            }#
            ## vectorized regression#
            tmp[[j]] <- lm(c(Z[,,start[j]:end[j]])~ -1 + XM )#
            bhat[j,] <- tmp[[j]]$coef#
        } #
        Zb <- Z - X.b.shrink(X, bhat, state)#
        bhat.mat <- matrix(NA, nstore, p*ns)#
    }#
    if (is.null(initial.s)){#
        s <- state## startS(Z, Time, m, initial.U, V, s2=1, R)#
    } else{#
        s <- initial.s#
    }#
    ## holder #
    ## Zm is a state-specific holder of ZE = Z - bhat#
    ## Zm[[1]] is a subset of Z pertaining to state 1#
    ## ZU = Z - ULU#
    ## ZY is original Z separated by state#
    UTA <- Km <- Zm <- ZY <- ZU <- ej <- U <- MU <- MU.state <- Xm <- Vm <- as.list(rep(NA, ns))#
    ps.store <- matrix(0, Time, ns)#
    ## given the state vector, initialize regime specific U and Vm#
    for (j in 1:ns){#
        ej[[j]] <- as.numeric(s==j)#
        Zm[[j]] <- Zb[,,ej[[j]]==1] #
        tmp <- eigen(apply(Zm[[j]], c(1,2), mean))#
        d2m <- abs(tmp$val)#
        U0 <- tmp$vec[, order(d2m, decreasing=TRUE) ]#
        U[[j]] <- matrix(U0[, 1:R], nrow=nrow(U0), ncol=R)#
        Vm[[j]] <- matrix(d2m[1:R], sum(s==j), R, byrow=TRUE)#
    }#
    V <- Reduce(rbind, Vm)#
    ## initialize MU and MU.state#
    ## MU is regime-specific mean matrix, the length of which depends on regime length#
    ## MU.state is a full-length mean matrix for state sampling#
    for (j in 1:ns){#
        MU[[j]] <-  M.U(list(U[[j]],U[[j]], Vm[[j]]))#
        MU.state[[j]] <-  M.U(list(U[[j]],U[[j]],V))#
    }#
    MUU <- abind(MU)#
#
    ## initialize s2 and d0#
    if (is.null(c0)){#
        c0 <- 1#
    }#
    if(is.null(d0)) {#
        d0 <- var(as.vector(Z - MU.state[[1]]))#
    }#
    s2 <- 1/rgamma(ns, c0/2, (d0)/2)#
    Pmat <- matrix(NA, nstore, ns)#
    ## cat("scale prior for sigma2: ", d0, "\n")#
    ## MCMC holders#
    ## outlier <- rep(0, T) ## count the number of times of -Inf#
    MU.record <- Umat <- s2mat <- iVU <- eU <- eV <- iVV <- eUmat <- iVUmat <- eVmat <- iVVmat <- as.list(rep(NA, ns))#
    for(j in 1:ns){#
        s2mat[[j]] <- matrix(NA, nstore)#
        Umat[[j]] <- matrix(NA, nstore, K[1]*R)#
        eUmat[[j]] <- matrix(NA, nstore, R)#
        iVUmat[[j]] <- matrix(NA, nstore, R*R)#
        eVmat[[j]]  <- matrix(NA, nstore, R)#
        iVVmat[[j]] <- matrix(NA, nstore, R*R)#
        MU.record[[j]] <- Y*0#
        iVU[[j]] <- diag(R)#
        eU[[j]] <- rep(u0, R)#
        iVV[[j]] <- diag(R)#
        eV[[j]] <- rep(v0, R)#
    }#
    Vmat <- matrix(NA, nstore, R*K[3])#
    Smat <- matrix(NA, nstore, K[3])#
    ## loglike holder#
    N.upper.tri <- K[1]*(K[1]-1)/2#
    ## Z.loglike <- matrix(NA, mcmc, K[3])#
    ## Z.loglike <- as(matrix(NA, mcmc, K[3]), "mpfr")#
    if(Waic){#
        Z.loglike.array <- array(NA, dim=c(nstore, N.upper.tri, K[3]))#
    }#
    logmarglike <- loglike <- logmarglike.upper <- loglike.upper <- NA#
#
    Zt <- matrix(NA,  Time,  N.upper.tri)#
    UTAsingle <-  upper.tri(Z[,,1])#
    ## UTA array: TRUE for upper triangle#
    UTAall <- Z*NA#
    for(k in 1:K[3]) {#
        UTAall[,,k] <-  upper.tri(Z[,,1] )#
    } #
    UTAall <- (UTAall==1)#
    Waic.out <- NA#
    SOS <- 0#
    if(verbose !=0){#
        cat("@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ \n")#
        cat("\t NetworkChangeReg Sampler Starts! \n")#
        ## cat("\t function called: ")#
        ## print(call)#
        cat("\t degree normalization: ", degree.normal, "\n")#
        cat("\t initial states: ", table(s), "\n")#
        cat("@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ \n")#
    }#
##############################################################
    ## MCMC loop starts!#
##############################################################
    for(iter in 1:totiter) {#
#
        ## Step 0. Update Z#
        ## update Z#
        ## pooling#
        if(pooling.mode == "time.pool"){#
            EZ <-  X.b(X,bhat) + MUU#
        }else if(pooling.mode == "time.specific"){#
            EZ <- X.b.specific(X, bhat) + MUU#
        }else{#
            EZ <- X.b.shrink(X, bhat, state=s) + MUU #
        }#
        for(y in sample(uy))#
        { #
            lb <- suppressWarnings(max(Z[Y<y & UTAall])) #
            ub <- suppressWarnings(min(Z[Y>y & UTAall]))#
            z <- qnorm(runif(sum(Y==y), pnorm( lb-EZ[Y==y] ), pnorm(ub-EZ[Y==y])))#
            Z[Y==y] <-  EZ[Y==y] + z#
            ## print(y)#
        }#
        ## Step 1. update ej, Km, Zm#
        ## cat("\n---------------------------------------------- \n ")#
        ## cat("Step 1. update ej, Km, Zm \n")#
        ## cat("\n---------------------------------------------- \n ")#
        for (j in 1:ns){#
            ej[[j]] <- as.numeric(s==j)#
            Km[[j]] <- dim(Zb[,,ej[[j]]==1])#
            ## in case state j has only 1 unit, force it to be an array with 1 length#
            if(is.na(Km[[j]][3])){#
                ZY[[j]] <- array(Z[,,ej[[j]]==1], dim = c(Km[[j]][1], Km[[j]][2], sum(ej[[j]]==1)))#
                Zm[[j]] <- array(Zb[,,ej[[j]]==1], dim = c(Km[[j]][1], Km[[j]][2], sum(ej[[j]]==1)))#
                Xm[[j]] <- array(X[,,ej[[j]]==1, ], dim = c(Km[[j]][1], Km[[j]][2], sum(ej[[j]]==1), p))#
                ## ZU[[j]] <- array(Z[,,ej[[j]]==1] - MU[[j]], dim = c(Km[[j]][1], Km[[j]][2], sum(ej[[j]]==1)))#
                 ## Ym[[j]] <- array(Y[,,ej[[j]]==1], dim = c(Km[[j]][1], Km[[j]][2], 1))#
            } else{#
                ZY[[j]] <- Z[,,ej[[j]]==1]#
                Zm[[j]] <- Zb[,,ej[[j]]==1]#
                Xm[[j]] <- array(X[,,ej[[j]]==1, ], dim = c(Km[[j]][1], Km[[j]][2], sum(ej[[j]]==1), p))#
                ## ZU[[j]] <- Z[,,ej[[j]]==1] - MU[[j]]#
                ## Ym[[j]] <- Y[,,ej[[j]]==1]#
            }#
            ## return the right dimension info#
            Km[[j]] <- dim(Zm[[j]])#
#
            ## UTA array: TRUE for upper triangle#
            UTA[[j]] <- Zm[[j]]*NA#
            for(k in 1:Km[[j]][3]) {#
                UTA[[j]][,,k] <-  upper.tri(Zm[[j]][,,1])#
            } #
            UTA[[j]] <- (UTA[[j]]==1)#
        }#
        ## Step 2. update U#
        ## cat("\n---------------------------------------------- \n ")#
        ## cat("Step 2. update U \n")#
        ## cat("\n---------------------------------------------- \n ")#
        U <- NetworkChange::updateUm(ns, U, V, R, Zm, Km, ej, s2, eU, iVU, UL.Normal)#
        ## Step 3. update V#
        ## cat("\n---------------------------------------------- \n ")#
        ## cat("Step 3. update V \n")#
        ## cat("\n---------------------------------------------- \n ")#
        Vm <- NetworkChange::updateVm(ns, U, V, Zm, Km, R, s2, eV, iVV, UTA)#
        V <- Reduce(rbind, Vm)#
#
        ## update MU#
        for(j in 1:ns){#
            ## MU is shorter than MU.state. MU.state is a full length.#
            MU[[j]] <- M.U(list(U[[j]],U[[j]],Vm[[j]]))#
            MU.state[[j]] <- M.U(list(U[[j]],U[[j]],V))#
            ZU[[j]] <- ZY[[j]] - MU[[j]]#
        }#
        MUU <- abind(MU)#
        ## Step 4. update s2#
        ## cat("\n---------------------------------------------- \n ")#
        ## cat("Step 4. update s2 \n")#
        ## cat("\n---------------------------------------------- \n ")#
        s2 <- NetworkChange::updates2m(ns, Zm, MU, c0, d0, Km)#
        ## update bhat#
        ## pooling#
        if(pooling.mode == "time.pool"){#
            ZE <- Z - MUU#
            Xtz <- t(apply(X0,4,c))%*%c(ZE)#
            cV <- solve( XtX + diag(1/100,p))#
            cE <- cV%*%Xtz#
            bhat <- rmvnorm(1,cE,cV)#
            Zb <-  Z- X.b(X, bhat)            #
        }else if(pooling.mode == "time.specific"){#
            for (t in 1:Time){#
                ZE <- Z[,,t] - MUU[,,t]#
                Xtz <-  t(apply(X0[,,t,],3,c))%*%c(ZE)#
                cV <- solve(XtX.specific[[t]] + diag(1/B0, p))#
                cE <- cV%*%Xtz#
                bhat[t, ] <- rmvnorm(1,cE,cV)#
            }#
            Zb <- Z - X.b.specific(X, bhat)            #
        }else{#
            end <- c(which(diff(s) == 1), Time)#
            start <- c(1, which(diff(s) == 1)+1)#
            for (j in 1:ns){#
                ZE <- ZY[[j]] - MU[[j]]#
                Xtz <-  t(apply(Xm[[j]],4,c))%*%c(ZE)#
                XtX.middle <- apply(Xm[[j]],c(1,2,3), function(x){x%*%t(x) } ) ## 16 66 66  8 array#
                XtX <- matrix(apply(XtX.middle, 1, sum), p, p)#
                cV <- solve( XtX + diag(1/B0,p))#
                cE <- cV%*%Xtz#
                ## vectorized regression#
                bhat[j,] <- rmvnorm(1,cE,cV)#
            } #
            Zb <- Z - X.b.shrink(X, bhat, state=s)#
        }#
        ## update hierarchical parameters#
        ## hierarchical parameters for U#
        for(j in 1:ns){#
            SS <-  t(U[[j]]) %*% U[[j]]## (Km[[j]][1]-1)*cov(U[[j]]) + Km[[j]][1]*msi/(Km[[j]][1]+1)#
            for(r in 1:R){#
                iVU[[j]][r,r] <- 1/rgamma(1, (u0 + K[1])/2, (u1+ SS[r,r])/2)#
            }#
            eU[[j]] <- c(NetworkChange:::rMVNorm(1,apply(U[[j]],2,sum)/(Km[[j]][1]+1), solve(iVU[[j]])/(Km[[j]][1]+1)))#
        }#
        ## hierarchical parameters for V#
        ## V for state j only#
        for(j in 1:ns){#
            Vs <- matrix(Vm[[j]], nrow=sum(ej[[j]]), ncol=R)#
            SS <-  t(Vs)%*%Vs#
            for(r in 1:R){#
                iVV[[j]][r,r] <- 1/rgamma(1, (v0 + Km[[j]][3])/2, (v1 + SS[r,r])/2)#
            }#
            eV[[j]] <- c(NetworkChange:::rMVNorm(1,apply(Vs, 2, sum)/(Km[[j]][3]+1),#
                                                 solve(iVV[[j]])/(Km[[j]][3]+1)))      #
        }#
        ## Step 5. update s#
        ## cat("\n---------------------------------------------- \n ")#
        ## cat("Step 5. update s \n")#
        ## cat("\n---------------------------------------------- \n ")#
        state.out <- NetworkChange::updateS(iter, s, V, m, Zb, Zt, Time, MU.state, P, s2,#
                             N.upper.tri, random.perturb)#
        ## state.out <- updateS(iter, s, V, m, Zb, Zt, Time, fast,#
        ##                       MU.state, P, s2, local.type, logistic.tune, N.upper.tri, sticky)#
        s <- state.out$s#
        ps <- state.out$ps#
        ## double check #
        if(length(table(s)) < ns){#
            ## print(table(s))#
            ## cat("Sampled s does not have all states. \n")#
            s <- sort(sample(1:ns, size=K[3], replace=TRUE, prob=(rep(1, ns))))#
        }#
        ## Step 6. update P#
        ## cat("\n---------------------------------------------- \n ")#
        ## cat("Step 6. update P \n")#
        ## cat("\n---------------------------------------------- \n ")       #
        P <- NetworkChange::updateP(s, ns, P, A0)#
        ## report#
        if (verbose!= 0 &iter %% verbose == 0){#
            cat("\n----------------------------------------------",'\n')#
            cat("    iteration = ", iter, '\n')#
            ## cat("    SOS = ", SOS, '\n')#
            cat("    beta = ", bhat,'\n')#
            if(plotZ == TRUE & plotUU == TRUE){#
                if(ns < 4){#
                    par(mfrow=c(1, ns+1))#
                } else{#
                    par(mfrow=c(2, ceiling((ns+1)/2)))#
                }#
            }#
            if(plotZ == TRUE){#
                plot(density(c(Z)), lwd=2, main="Density of Z and MU.state")#
                for(j in 1:ns){lines(density(c(MU.state[[j]])), col=1+j)}#
                legend("topright", paste0("Regime", 1:ns), col=2:(ns+1), lty=1, lwd=1)#
            }#
            if(plotZ == FALSE & plotUU == TRUE){#
                par(mfrow=c(1, ns))#
            }#
            for(j in 1:ns){#
                cat("    state ", j, "has :", sum(s==j),'\n')#
                cat("    sigma2 at state", j, "=", s2[j] ,'\n')#
                if(plotUU == TRUE){#
                    plot(U[[j]][,1], U[[j]][, 2], pch=19, cex=1); abline(v=0, col=2); abline(h=0, col=2)#
                }           #
            }#
            cat("----------------------------------------------",'\n')#
        }#
        ## save#
        if (iter > burnin & (iter-burnin)%%thin == 0){#
            nss <- nss + 1#
#
            bhat.mat[iter-burnin, ] <- bhat#
#
            for(j in 1:ns){#
                MU.record[[j]] <- MU.record[[j]] + MU.state[[j]]#
                s2mat[[j]][(iter-burnin)/thin] <- s2[j]#
                Umat[[j]][(iter-burnin)/thin, ] <- as.vector(U[[j]])#
                eUmat[[j]][(iter-burnin)/thin, ] <- as.vector(eU[[j]])#
                iVUmat[[j]][(iter-burnin)/thin, ] <- as.vector(iVU[[j]])#
                eVmat[[j]][(iter-burnin)/thin, ] <- as.vector(eV[[j]])#
                iVVmat[[j]][(iter-burnin)/thin, ] <- as.vector(iVV[[j]])#
            }#
            Vmat[(iter-burnin)/thin, ] <- as.vector(V)#
            Smat[(iter-burnin)/thin, ] <- s#
            Pmat[(iter-burnin)/thin, ] <- diag(P)#
            ps.store <- ps.store + ps#
            if(Waic){#
                d <- sapply(1:K[3], function(t){dnorm(c(Zb[,,t][UTAsingle]),#
                                                      mean = c(MU.state[[s[t]]][,,t][UTAsingle]),#
                                                      sd=sqrt(s2[[s[t]]]), log=TRUE)})#
                Z.loglike.array[(iter-burnin)/thin, ,] <- d#
            }#
        }#
    }## end of MCMC loop
pos = function(x,s) (x-s)*(x&gt;=s)
pos = function(x,s) (x-s)*(x>=s)
x <- rnorm(100)
pos(x, 0.5)
x
myocarde=read.table("http://freakonometrics.free.fr/myocarde.csv", head=TRUE ,sep=";")#
#
y = myocarde$PRONO#
X = cbind(1,as.matrix(myocarde[,1:7]))#
negLogLik = function(beta){#
    -sum(-y*log(1 + exp(-(X%*%beta))) - (1-y)*log(1 + exp(X%*%beta)))#
}
pos = function(x,s) (x-s)*(x>=s)## pos = function(x,s) (x-s)*(x&gt;=s)#
#
reg = glm(PRONO~INSYS+pos(INSYS,15)+#
              pos(INSYS,25), data=myocarde,family=binomial)
myocarde[1,]
myocarde$PRONO
pos(myocarde$INSYS,15)
pos(INSYS,15)
pos(myocardeINSYS,15)
pos(myocarde$INSYS,15)
pos = function(x,s) (x-s)*(x>=s)## pos = function(x,s) (x-s)*(x&gt;=s)
pos(myocarde$INSYS,15)
myocarde$INSYS
reg = glm(PRONO~INSYS, data=myocarde,family=binomial)
31800/30
16300/1060
38.40/28.41
19.2/14.77
24/28/41
24/28.41
3125000000000
3125000000000/1000000000
120/3125
120/398.980
120/1256.018
getwd()
devtools::document()
set.seed(11173)#
N <- 10#
n.block <- 3#
Yarr <- MakeBlockNetworkChange(n=N, break.point = .5, #
                               base.prob=.2, block.prob=.5,#
                               shape=1, T=20, type ="split")#
Y1 <- Yarr[,,16]#
Y2 <- 1-Yarr[,,20]#
diag(Y2) <- 0#
Y <- abind(Y1, Y2, along=3)
require(abind)
set.seed(11173)#
N <- 10#
n.block <- 3#
Yarr <- MakeBlockNetworkChange(n=N, break.point = .5, #
                               base.prob=.2, block.prob=.5,#
                               shape=1, T=20, type ="split")#
Y1 <- Yarr[,,16]#
Y2 <- 1-Yarr[,,20]#
diag(Y2) <- 0#
Y <- abind(Y1, Y2, along=3)
K <- dim(Y)
Y <- Yarr#
K <- dim(Y)#
#
## data split
K
train_rows <- sort(sample(1:ntime, train.ratio*ntime, prob=rep(1/ntime, ntime)))
ntime <- K[3]#
train.ratio=0.5#
#
train_rows <- sort(sample(1:ntime, train.ratio*ntime, prob=rep(1/ntime, ntime)))
train_rows
y.train <- Y[,,train_rows]#
y.test <- Y[,,-train_rows]
G <- 100#
right <- NetworkStatic(y.train, R=2,  mcmc = G, burnin = G, constant=FALSE, verbose= G)#
wrong <-  NetworkChange(y.train, m = 1, R=2,  mcmc = G, burnin = G, constant=FALSE, verbose= G)
m0 <- right
m1 <- wrong
Z.test <- y.test#
for(k in 1:K[3]){#
    ee <- eigen(y.test[,,k])#
    Z.test[,,k] <- y.test[,,k] - ee$values[1] * outer(ee$vectors[,1], ee$vectors[,1])#
}
Z.test <- y.test#
K.test <- dim(y.test)#
for(k in 1:K.test[3]){#
    ee <- eigen(y.test[,,k])#
    Z.test[,,k] <- y.test[,,k] - ee$values[1] * outer(ee$vectors[,1], ee$vectors[,1])#
}
dim(m0)
dim(m1)
m1
m1[[1]]
dim(m0)
dim(m1)
dim(m1[[1]])
dim(m1[[2]])
dim(m1[[3]])
devtools::document()
set.seed(11173)#
N <- 10#
n.block <- 3#
Yarr <- MakeBlockNetworkChange(n=N, break.point = .5, #
                               base.prob=.2, block.prob=.5,#
                               shape=1, T=20, type ="split")#
Y <- Yarr#
K <- dim(Y)#
#
## data split#
ntime <- K[3]#
train.ratio=0.5#
#
train_rows <- sort(sample(1:ntime, train.ratio*ntime, prob=rep(1/ntime, ntime)))#
y.train <- Y[,,train_rows]#
y.test <- Y[,,-train_rows]
G <- 100#
m0 <- NetworkStatic(y.train, R=2,  mcmc = G, burnin = G, constant=FALSE, verbose= G)
m1 <-  NetworkChange(y.train, m = 1, R=2,  mcmc = G, burnin = G, verbose= G, initial.s = sort(rep(1:2, length=Time)))
Time <- dim(Y)[[3]]
m1 <-  NetworkChange(y.train, m = 1, R=2,  mcmc = G, burnin = G, verbose= G, initial.s = sort(rep(1:2, length=Time)))
Time
, initial.s = sort(rep(1:2, length=Time))
initial.s = sort(rep(1:2, length=Time))
initial.s
Time <- dim(y.train)[[3]]
m1 <-  NetworkChange(y.train, m = 1, R=2,  mcmc = G, burnin = G, verbose= G, initial.s = sort(rep(1:2, length=Time)))
devtools::document()
m1 <-  NetworkChange(y.train, m = 1, R=2,  mcmc = G, burnin = G, verbose= G, initial.s = sort(rep(1:2, length=Time)))
Z.test <- y.test#
K.test <- dim(y.test)#
for(k in 1:K.test[3]){#
    ee <- eigen(y.test[,,k])#
    Z.test[,,k] <- y.test[,,k] - ee$values[1] * outer(ee$vectors[,1], ee$vectors[,1])#
}
dim(m0)
dim(m1)
sum((Z.test - m0)^2)
sum((Z.test - m1)^2)
m2 <-  NetworkChange(y.train, m = 2, R=2,  mcmc = G, burnin = G, verbose= G, initial.s = sort(rep(1:3, length=Time)))
m3 <-  NetworkChange(y.train, m = 3, R=2,  mcmc = G, burnin = G, verbose= G, initial.s = sort(rep(1:4, length=Time)))
mse <- matrix(NA, 2, 4)
mse0 <- sum((Z.test - m0)^2)#
mse1 <- sum((Z.test - m1)^2)#
mse2 <- sum((Z.test - m2)^2)#
mse3 <- sum((Z.test - m3)^2)#
#
mse[1,] <- c(mse0, mse1, mse2, mse3)
mse
## test -> train#
Z.train <- y.train#
K.train <- dim(y.train)#
for(k in 1:K.train[3]){#
    ee <- eigen(y.train[,,k])#
    Z.train[,,k] <- y.train[,,k] - ee$values[1] * outer(ee$vectors[,1], ee$vectors[,1])#
}#
#
m0 <- NetworkStatic(y.test, R=2,  mcmc = G, burnin = G, verbose= G)#
m1 <-  NetworkChange(y.test, m = 1, R=2,  mcmc = G, burnin = G, verbose= G, initial.s = sort(rep(1:2, length=Time)))#
m2 <-  NetworkChange(y.test, m = 2, R=2,  mcmc = G, burnin = G, verbose= G, initial.s = sort(rep(1:3, length=Time)))#
m3 <-  NetworkChange(y.test, m = 3, R=2,  mcmc = G, burnin = G, verbose= G, initial.s = sort(rep(1:4, length=Time)))#
#
mse0 <- sum((Z.train - m0)^2)#
mse1 <- sum((Z.train - m1)^2)#
mse2 <- sum((Z.train - m2)^2)#
mse3 <- sum((Z.train - m3)^2)#
#
mse[2,] <- c(mse0, mse1, mse2, mse3)
mse
install.packages("plyr")#
install.packages("dplyr")#
install.packages("randomForest")#
출처: http://daryan.tistory.com/21 [Ryan의 데이터 과학 블로그]
library(plyr)#
library(dplyr)#
library(randomForest)#
출처: http://daryan.tistory.com/21 [Ryan의 데이터 과학 블로그]
ata <- iris#
#그 유명한 iris data set을 가지고 오기때문에 단순한 명령어가 가능합니다.#
#
glimpse(data)#
#데이터 확인해보는 명령어#
#
#cross validation, using rf to predict sepal.length#
k = 5#
#
data$id <- sample(1:k, nrow(data), replace = TRUE)#
list <- 1:k#
출처: http://daryan.tistory.com/21 [Ryan의 데이터 과학 블로그]
data <- iris#
#그 유명한 iris data set을 가지고 오기때문에 단순한 명령어가 가능합니다.#
#
glimpse(data)#
#데이터 확인해보는 명령어#
#
#cross validation, using rf to predict sepal.length#
k = 5#
#
data$id <- sample(1:k, nrow(data), replace = TRUE)#
list <- 1:k#
# prediction and test set data frames that we add to with each iteration over#
# the folds#
prediction <- data.frame()#
testsetCopy <- data.frame()#
출처: http://daryan.tistory.com/21 [Ryan의 데이터 과학 블로그]
data
prediction <- data.frame()#
testsetCopy <- data.frame()#
출처: http://daryan.tistory.com/21 [Ryan의 데이터 과학 블로그]
progress.bar <- create_progress_bar("text")#
progress.bar$init(k)#
출처: http://daryan.tistory.com/21 [Ryan의 데이터 과학 블로그]
for(i in 1:k){#
  # remove rows with id i from dataframe to create training set#
  # select rows with id i to create test set#
  trainingset <- subset(data, id %in% list[-i])#
  testset <- subset(data, id %in% c(i))#
  #데이터를 5등분하고 한번 뽑은 test data가 다시 train 으로 가지 않도록 5등분 합니다.#
#
  #run a random forest model#
  mymodel <- randomForest(trainingset$Sepal.Length ~ ., data = trainingset, ntree = 100)#
  #랜덤 포레스트 알고리즘으로 꽃받침의 길이를 나머지 데이터로 예측하는 모델을 만듭니다.#
#
  #remove response column 1, Sepal.Length#
  temp <- as.data.frame(predict(mymodel, testset[,-1]))#
#
  # append this iteration's predictions to the end of the prediction data frame#
  prediction <- rbind(prediction, temp)#
#
  # append this iteration's test set to the test set copy data frame#
  # keep only the Sepal Length Column#
  testsetCopy <- rbind(testsetCopy, as.data.frame(testset[,1]))#
#
  progress.bar$step()#
}#
출처: http://daryan.tistory.com/21 [Ryan의 데이터 과학 블로그]
k
trainingset <- subset(data, id %in% list[-i])#
  testset <- subset(data, id %in% c(i))
trainingset
dim(traininingset)
dim(trainingset)
dim(testset)
i
dim(data)
i = 2
trainingset <- subset(data, id %in% list[-i])#
  testset <- subset(data, id %in% c(i))
dim(trainingset)
dim(testset)
data$id
table(data$id)
progress.bar$step()
k
progress.bar <- create_progress_bar("text")#
progress.bar$init(k)
progress.bar <- create_progress_bar("text")#
    progress.bar$init(k)#
    K <- dim(Y)#
    ntime <- K[3]#
    train.ratio <- 1/k.fold#
    G <- mcmc
k.fold=2
MSE <- matrix(NA, length(bound:(ntime-bound)), break.upper)#
        count <- 1#
        for(t in bound:(ntime-bound)){#
            y.train <- Y[,,-t]#
            y.test <- Y[,,t]#
            m0 <- NetworkStatic(y.train, R=2,  mcmc = G, burnin = G, verbose= G)#
            m1 <-  NetworkChange(y.train, m = 1, R=2,  mcmc = G, burnin = G, verbose= G, initial.s = sort(rep(1:2, length=Time)))#
            m2 <-  NetworkChange(y.train, m = 2, R=2,  mcmc = G, burnin = G, verbose= G, initial.s = sort(rep(1:3, length=Time)))#
            m3 <-  NetworkChange(y.train, m = 3, R=2,  mcmc = G, burnin = G, verbose= G, initial.s = sort(rep(1:4, length=Time)))#
            mse0 <- sum((Z.test - m0)^2)#
            mse1 <- sum((Z.test - m1)^2)#
            mse2 <- sum((Z.test - m2)^2)#
            mse3 <- sum((Z.test - m3)^2)#
            MSE[count, ] <- c(mse0, mse1, mse2, mse3)#
            count <- count + 1#
            progress.bar$step()#
        }
bound=2
MSE <- matrix(NA, length(bound:(ntime-bound)), break.upper)#
        count <- 1#
        for(t in bound:(ntime-bound)){#
            y.train <- Y[,,-t]#
            y.test <- Y[,,t]#
            m0 <- NetworkStatic(y.train, R=2,  mcmc = G, burnin = G, verbose= G)#
            m1 <-  NetworkChange(y.train, m = 1, R=2,  mcmc = G, burnin = G, verbose= G, initial.s = sort(rep(1:2, length=Time)))#
            m2 <-  NetworkChange(y.train, m = 2, R=2,  mcmc = G, burnin = G, verbose= G, initial.s = sort(rep(1:3, length=Time)))#
            m3 <-  NetworkChange(y.train, m = 3, R=2,  mcmc = G, burnin = G, verbose= G, initial.s = sort(rep(1:4, length=Time)))#
            mse0 <- sum((Z.test - m0)^2)#
            mse1 <- sum((Z.test - m1)^2)#
            mse2 <- sum((Z.test - m2)^2)#
            mse3 <- sum((Z.test - m3)^2)#
            MSE[count, ] <- c(mse0, mse1, mse2, mse3)#
            count <- count + 1#
            progress.bar$step()#
        }
MSE <- matrix(NA, length(bound:(ntime-bound)), break.upper)#
        count <- 1#
        for(t in bound:(ntime-bound)){#
            y.train <- Y[,,-t]#
            y.test <- Y[,,t]#
            Time <- dim(y.train)[3]#
            m0 <- NetworkStatic(y.train, R=2,  mcmc = G, burnin = G, verbose= G)#
            m1 <-  NetworkChange(y.train, m = 1, R=2,  mcmc = G, burnin = G, verbose= G, initial.s = sort(rep(1:2, length=Time)))#
            m2 <-  NetworkChange(y.train, m = 2, R=2,  mcmc = G, burnin = G, verbose= G, initial.s = sort(rep(1:3, length=Time)))#
            m3 <-  NetworkChange(y.train, m = 3, R=2,  mcmc = G, burnin = G, verbose= G, initial.s = sort(rep(1:4, length=Time)))#
            mse0 <- sum((Z.test - m0)^2)#
            mse1 <- sum((Z.test - m1)^2)#
            mse2 <- sum((Z.test - m2)^2)#
            mse3 <- sum((Z.test - m3)^2)#
            MSE[count, ] <- c(mse0, mse1, mse2, mse3)#
            count <- count + 1#
            progress.bar$step()#
        }
Z.test <- y.test#
            K.test <- dim(y.test)#
            for(k in 1:K.test[3]){#
                ee <- eigen(y.test[,,k])#
                Z.test[,,k] <- y.test[,,k] - ee$values[1] * outer(ee$vectors[,1], ee$vectors[,1])#
            }
K.test
Z.test <- y.test#
            ee <- eigen(y.test)#
            Z.test <- y.test - ee$values[1] * outer(ee$vectors[,1], ee$vectors[,1])
mse0 <- sum((Z.test - m0)^2)#
            mse1 <- sum((Z.test - m1)^2)#
            mse2 <- sum((Z.test - m2)^2)#
            mse3 <- sum((Z.test - m3)^2)#
            MSE[count, ] <- c(mse0, mse1, mse2, mse3)
Z.test
dim(m0)
apply(m0, 1:2, mean)
mse0 <- sum((Z.test - apply(m0, 1:2, mean))^2)#
            mse1 <- sum((Z.test - apply(m1, 1:2, mean))^2)#
            mse2 <- sum((Z.test - apply(m2, 1:2, mean))^2)#
            mse3 <- sum((Z.test - apply(m3, 1:2, mean))^2)#
            MSE[count, ] <- c(mse0, mse1, mse2, mse3)
MSE <- matrix(NA, length(bound:(ntime-bound)), break.upper)
break.upper = 3
MSE <- matrix(NA, length(bound:(ntime-bound)), break.upper)
mse0 <- sum((Z.test - apply(m0, 1:2, mean))^2)#
            mse1 <- sum((Z.test - apply(m1, 1:2, mean))^2)#
            mse2 <- sum((Z.test - apply(m2, 1:2, mean))^2)#
            mse3 <- sum((Z.test - apply(m3, 1:2, mean))^2)#
            MSE[count, ] <- c(mse0, mse1, mse2, mse3)
count
c(mse0, mse1, mse2, mse3)
MSE <- matrix(NA, length(bound:(ntime-bound)), break.upper+1)
MSE[count, ] <- c(mse0, mse1, mse2, mse3)
MSE
MSE <- matrix(NA, length(bound:(ntime-bound)), break.upper+1)#
        count <- 1#
        for(t in bound:(ntime-bound)){#
            y.train <- Y[,,-t]#
            y.test <- Y[,,t]#
            Time <- dim(y.train)[3]#
            m0 <- NetworkStatic(y.train, R=2,  mcmc = G, burnin = G, verbose= G)#
            m1 <-  NetworkChange(y.train, m = 1, R=2,  mcmc = G, burnin = G, verbose= G, initial.s = sort(rep(1:2, length=Time)))#
            m2 <-  NetworkChange(y.train, m = 2, R=2,  mcmc = G, burnin = G, verbose= G, initial.s = sort(rep(1:3, length=Time)))#
            m3 <-  NetworkChange(y.train, m = 3, R=2,  mcmc = G, burnin = G, verbose= G, initial.s = sort(rep(1:4, length=Time)))#
#
            Z.test <- y.test#
            ee <- eigen(y.test)#
            Z.test <- y.test - ee$values[1] * outer(ee$vectors[,1], ee$vectors[,1])#
            mse0 <- sum((Z.test - apply(m0, 1:2, mean))^2)#
            mse1 <- sum((Z.test - apply(m1, 1:2, mean))^2)#
            mse2 <- sum((Z.test - apply(m2, 1:2, mean))^2)#
            mse3 <- sum((Z.test - apply(m3, 1:2, mean))^2)#
            MSE[count, ] <- c(mse0, mse1, mse2, mse3)#
            count <- count + 1#
            progress.bar$step()#
        }
MSE
apply(MSE, 2, mean)
k.fold=3
train.ratio <- 1/k.fold
train_rows <- sort(sample(1:ntime, train.ratio*ntime, prob=rep(1/ntime, ntime)))
train_rows
sample(1:ntime, train.ratio*ntime, prob=rep(1/ntime, ntime))
sample(1:ntime, ntime, prob=rep(1/ntime, ntime))
require(caret)#
flds <- createFolds(y, k = 10, list = TRUE, returnTrain = FALSE)#
names(flds)[1] <- "train"
install.packages(ddalpha)
install.packages("ddalpha")
require(caret)#
flds <- createFolds(y, k = 10, list = TRUE, returnTrain = FALSE)#
names(flds)[1] <- "train"
install.packages("caret")
require(caret)#
flds <- createFolds(y, k = 10, list = TRUE, returnTrain = FALSE)#
names(flds)[1] <- "train"
install.packages("kernlab")
require(caret)#
flds <- createFolds(y, k = 10, list = TRUE, returnTrain = FALSE)#
names(flds)[1] <- "train"
y <- 1:20
require(caret)#
flds <- createFolds(y, k = 10, list = TRUE, returnTrain = FALSE)#
names(flds)[1] <- "train"
flds
createFolds
cut(seq(1, 1:ntime, breaks=k.fold, labels=FALSE)
)
cut(seq(1, 1:ntime), breaks=k.fold, labels=FALSE)
seq(1, n.time)
seq(1, ntime)
cut(seq(1, ntime), breaks=k.fold, labels=FALSE)
sample(ntime)
sort(sample(ntime))
G
G=10
train.ratio <- 1/k.fold#
        MSE <- matrix(NA, k.fold, break.upper+1)#
        count <- 1
k.fold
for(i in 1:k.fold){#
            ## train set#
            train_rows <- sort(sample(1:ntime, train.ratio*ntime, prob=rep(1/ntime, ntime)))#
            y.train <- Y[,,train_rows]#
            Time <- dim(y.train)[3]#
            ## test set#
            y.test <- Y[,,-train_rows]#
            Z.test <- y.test#
            K.test <- dim(y.test)#
            for(k in 1:K.test[3]){#
                ee <- eigen(y.test[,,k])#
                Z.test[,,k] <- y.test[,,k] - ee$values[1] * outer(ee$vectors[,1], ee$vectors[,1])#
            }#
            ## list object storage#
            m.out <- mse <- as.list(rep(NA, break.upper))#
#
            ## fit a break specific model#
            m0 <- NetworkStatic(y.train, R=2,  mcmc = G, burnin = G, verbose= 0)#
            for(m in 1:break.upper){#
                m.out[[m]] <- NetworkChange(y.train, m = m, R=2,  mcmc = G, burnin = G, verbose= 0, initial.s = sort(rep(1:(m+1), length=Time)))#
            }#
            ## compute mse#
            mse0 <- sum((Z.test - apply(m0, 1:2, mean))^2)#
            for(m in 1:break.upper){#
                mse[[m]] <- sum((apply(Z.test, 1:2, mean) - apply(m.out[[m]], 1:2, mean))^2)#
            }#
#
            ## save#
            MSE[count, ] <- c(mse0, unlist(mse))#
            count <- count + 1#
            progress.bar$step()#
        }
devtools::document()
train.ratio <- 1/k.fold#
        MSE <- matrix(NA, k.fold, break.upper+1)#
        count <- 1#
        for(i in 1:k.fold){#
            ## train set#
            train_rows <- sort(sample(1:ntime, train.ratio*ntime, prob=rep(1/ntime, ntime)))#
            y.train <- Y[,,train_rows]#
            Time <- dim(y.train)[3]#
            ## test set#
            y.test <- Y[,,-train_rows]#
            Z.test <- y.test#
            K.test <- dim(y.test)#
            for(k in 1:K.test[3]){#
                ee <- eigen(y.test[,,k])#
                Z.test[,,k] <- y.test[,,k] - ee$values[1] * outer(ee$vectors[,1], ee$vectors[,1])#
            }#
            ## list object storage#
            m.out <- mse <- as.list(rep(NA, break.upper))#
#
            ## fit a break specific model#
            m0 <- NetworkStatic(y.train, R=2,  mcmc = G, burnin = G, verbose= 0)#
            for(m in 1:break.upper){#
                m.out[[m]] <- NetworkChange(y.train, m = m, R=2,  mcmc = G, burnin = G, verbose= 0, initial.s = sort(rep(1:(m+1), length=Time)))#
            }#
            ## compute mse#
            mse0 <- sum((apply(Z.test, 1:2, mean) - apply(m0, 1:2, mean))^2)#
            for(m in 1:break.upper){#
                mse[[m]] <- sum((apply(Z.test, 1:2, mean) - apply(m.out[[m]], 1:2, mean))^2)#
            }#
#
            ## save#
            MSE[count, ] <- c(mse0, unlist(mse))#
            count <- count + 1#
            progress.bar$step()#
        }#
    }
MSE
apply(MSE, 2, mean)
G
progress.bar <- create_progress_bar("text")#
        progress.bar$init(k.fold*break.upper)#
        train.ratio <- 1/k.fold#
        MSE <- matrix(NA, k.fold, break.upper+1)#
        count <- 1#
        for(i in 1:k.fold){#
            ## train set#
            train_rows <- sort(sample(1:ntime, train.ratio*ntime, prob=rep(1/ntime, ntime)))#
            y.train <- Y[,,train_rows]#
            Time <- dim(y.train)[3]#
            ## test set#
            y.test <- Y[,,-train_rows]#
            Z.test <- y.test#
            K.test <- dim(y.test)#
            for(k in 1:K.test[3]){#
                ee <- eigen(y.test[,,k])#
                Z.test[,,k] <- y.test[,,k] - ee$values[1] * outer(ee$vectors[,1], ee$vectors[,1])#
            }#
            ## list object storage#
            m.out <- mse <- as.list(rep(NA, break.upper))#
#
            ## fit a break specific model#
            m0 <- NetworkStatic(y.train, R=2,  mcmc = G, burnin = G, verbose= 0)#
            for(m in 1:break.upper){#
                m.out[[m]] <- NetworkChange(y.train, m = m, R=2,  mcmc = G, burnin = G, verbose= 0, initial.s = sort(rep(1:(m+1), length=Time)))#
            }#
            ## compute mse#
            mse0 <- sum((apply(Z.test, 1:2, mean) - apply(m0, 1:2, mean))^2)#
            for(m in 1:break.upper){#
                mse[[m]] <- sum((apply(Z.test, 1:2, mean) - apply(m.out[[m]], 1:2, mean))^2)#
            }#
#
            ## save#
            MSE[count, ] <- c(mse0, unlist(mse))#
            count <- count + 1#
            progress.bar$step()#
        }
progress.bar <- create_progress_bar("text")#
        progress.bar$init(k.fold)#
        train.ratio <- 1/k.fold#
        MSE <- matrix(NA, k.fold, break.upper+1)#
        count <- 1#
        for(i in 1:k.fold){#
            ## train set#
            train_rows <- sort(sample(1:ntime, train.ratio*ntime, prob=rep(1/ntime, ntime)))#
            y.train <- Y[,,train_rows]#
            Time <- dim(y.train)[3]#
            ## test set#
            y.test <- Y[,,-train_rows]#
            Z.test <- y.test#
            K.test <- dim(y.test)#
            for(k in 1:K.test[3]){#
                ee <- eigen(y.test[,,k])#
                Z.test[,,k] <- y.test[,,k] - ee$values[1] * outer(ee$vectors[,1], ee$vectors[,1])#
            }#
            ## list object storage#
            m.out <- mse <- as.list(rep(NA, break.upper))#
#
            ## fit a break specific model#
            m0 <- NetworkStatic(y.train, R=2,  mcmc = G, burnin = G, verbose= 0)#
            for(m in 1:break.upper){#
                m.out[[m]] <- NetworkChange(y.train, m = m, R=2,  mcmc = G, burnin = G, verbose= 0, initial.s = sort(rep(1:(m+1), length=Time)))#
            }#
            ## compute mse#
            mse0 <- sum((apply(Z.test, 1:2, mean) - apply(m0, 1:2, mean))^2)#
            for(m in 1:break.upper){#
                mse[[m]] <- sum((apply(Z.test, 1:2, mean) - apply(m.out[[m]], 1:2, mean))^2)#
            }#
#
            ## save#
            MSE[count, ] <- c(mse0, unlist(mse))#
            count <- count + 1#
            progress.bar$step()#
        }
MSE
devtools::document()
set.seed(11173)#
N <- 5#
Y <- MakeBlockNetworkChange(n=N, break.point = .5, #
                            base.prob=.2, block.prob=.5,#
                            shape=1, T=20, type ="split")#
MSE <- NetworkChangeCVtest(Y, R=2, k.fold = 2, mcmc=G, burnin=G, verbose=0,#
                           LOO=FALSE, LOO.bound=2, break.upper = 3)#
apply(MSE, 2, mean)
set.seed(11173)#
N <- 10#
Y <- MakeBlockNetworkChange(n=N, break.point = .5, #
                            base.prob=.2, block.prob=.5,#
                            shape=1, T=20, type ="split")#
MSE <- NetworkChangeCVtest(Y, R=2, k.fold = 2, mcmc=G, burnin=G, verbose=0,#
                           LOO=FALSE, LOO.bound=2, break.upper = 3)#
apply(MSE, 2, mean)
set.seed(11173)#
N <- 20#
Y <- MakeBlockNetworkChange(n=N, break.point = .5, #
                            base.prob=.2, block.prob=.5,#
                            shape=1, T=20, type ="split")#
MSE <- NetworkChangeCVtest(Y, R=2, k.fold = 2, mcmc=G, burnin=G, verbose=0,#
                           LOO=FALSE, LOO.bound=2, break.upper = 3)#
apply(MSE, 2, mean)
set.seed(11173)#
N <- 20#
Y <- MakeBlockNetworkChange(n=N, break.point = .5, #
                            base.prob=.2, block.prob=.5,#
                            shape=1, T=40, type ="split")#
MSE <- NetworkChangeCVtest(Y, R=2, k.fold = 2, mcmc=G, burnin=G, verbose=0,#
                           LOO=FALSE, LOO.bound=2, break.upper = 3)#
apply(MSE, 2, mean)
MSE <- NetworkChangeCVtest(Y, R=2, k.fold = 2, mcmc=G, burnin=G, verbose=0,#
                           LOO=TRUE, LOO.bound=2, break.upper = 3)#
apply(MSE, 2, mean)
}
}#
1
}#
1#
ㅂ()
}#
1#
ㅂ()#
q()
